{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Activation,Flatten\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AUDCAD/AUD_CAD_rev.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRYP event embedding\n",
    "GRYP_IDX = {}\n",
    "for idx, value in enumerate( list(data.event.unique())):\n",
    "    GRYP_IDX[value] = idx\n",
    "\n",
    "data['event'].replace(GRYP_IDX, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to index and change -1 to 2\n",
    "REPLACE_INDEX = {'buy':0, 'hold':1, 'sell':2, -1:2}\n",
    "data.replace(REPLACE_INDEX, inplace= True)\n",
    "# one hot label index\n",
    "BUY_HOLD_SELL_INDEX = {'buy': [0,1,0,0], 'hold': [0,0,1,0], 'sell': [0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all nan\n",
    "print(f'before: {data.shape}')\n",
    "data.dropna(subset=['min_40', 'ratio top'],inplace=True)\n",
    "data = data.reset_index(drop=True)\n",
    "# train val test split \n",
    "Xtrain = data[(data['datetime']>='2018-06-25T09:00:00.000000000Z') & ((data['datetime']<='2021-09-13T00:45:00.000000000Z'))]\n",
    "Xtrain.reset_index(drop=True, inplace=True)\n",
    "Xvalid = data[(data['datetime']>='2021-09-13T01:00:00.000000000Z') & ((data['datetime']<='2022-02-04T07:45:00.000000000Z'))]\n",
    "Xvalid.reset_index(drop=True, inplace=True)\n",
    "Xtest = data[(data['datetime']>='2022-02-04T08:00:00.000000000Z') & ((data['datetime']<='2022-06-30T13:30:00.000000000Z'))]\n",
    "Xtest.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'after remove null values: {data.shape} \\ntrain size: {train_size}\\nvalidtion size: {valid_size}\\ntest size: {test_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(data, window_size):\n",
    "    train_dt_ori, train_dt_scaled, target_minprice, target_maxprice, target_minp_scaled,\\\n",
    "    target_maxp_scaled, price_scaler_max, price_scaler_min = [], [], [], [], [], [], [], []\n",
    "\n",
    "    train_dt_bb1,train_dt_bb2,train_dt_bb3,train_dt_bb4,train_dt_bb5,train_dt_bb6,train_dt_bb7,train_dt_bb8 = [], [], [], [], [], [], [], []\n",
    "    train_dt_trend,train_dt_change,train_dt_break=[],[],[]\n",
    "    train_dt_rsi15,train_dt_rsi25,train_dt_rsi35 = [], [], []\n",
    "    train_dt_wr_atr=[]\n",
    "    target_bhs = []\n",
    "\n",
    "    seqlen = window_size # change window size according to labelï¼\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    for index, row in data.iterrows(): \n",
    "        if index <= len(data)-seqlen:\n",
    "            # OHLC numerical\n",
    "            train_dt_ori.append(data.loc[index:seqlen-1+index, ['open', 'high', 'low', 'close']].values)\n",
    "            # Categorical\n",
    "            train_dt_bb1.append(data.loc[index:seqlen-1+index, ['bb_event1']].values)\n",
    "            train_dt_bb2.append(data.loc[index:seqlen-1+index, ['bb_event2']].values)\n",
    "            train_dt_bb3.append(data.loc[index:seqlen-1+index, ['bb_event3']].values)\n",
    "            train_dt_bb4.append(data.loc[index:seqlen-1+index, ['bb_event4']].values)\n",
    "            train_dt_bb5.append(data.loc[index:seqlen-1+index, ['bb_event5']].values)\n",
    "            train_dt_bb6.append(data.loc[index:seqlen-1+index, ['bb_event6']].values)\n",
    "            train_dt_bb7.append(data.loc[index:seqlen-1+index, ['bb_event7']].values)\n",
    "            train_dt_bb8.append(data.loc[index:seqlen-1+index, ['bb_event8']].values)\n",
    "            train_dt_trend.append(data.loc[index:seqlen-1+index, ['Trend']].values)\n",
    "            train_dt_change.append(data.loc[index:seqlen-1+index, ['Change']].values)\n",
    "            train_dt_break.append(data.loc[index:seqlen-1+index, ['Break']].values)\n",
    "            train_dt_rsi15.append(data.loc[index:seqlen-1+index, ['rsi15']].values)\n",
    "            train_dt_rsi25.append(data.loc[index:seqlen-1+index, ['rsi25']].values)\n",
    "            train_dt_rsi35.append(data.loc[index:seqlen-1+index, ['rsi35']].values)\n",
    "            \n",
    "            # numerical scale\n",
    "            train_dt_wr_atr.append(scaler.fit_transform(data.loc[index:seqlen-1+index, ['wr15', 'wr25', 'wr35', 'atr15', 'atr25','atr35']].values))\n",
    "            # min max scale within windows size\n",
    "            train_dt_scaled.append(scaler.fit_transform(data.loc[index:seqlen-1+index, ['open', 'high', 'low', 'close']].values)\n",
    "                                   \n",
    "            # every window size/seq length predict min_10 label\n",
    "            tmp_minprice = data.loc[seqlen-1+index, f'min_{window_size}'].tolist()\n",
    "            target_minprice.append(tmp_minprice)\n",
    "            # every window size/seq length predict max_10 label\n",
    "            tmp_maxprice = data.loc[seqlen-1+index, f'max_{window_size}'].tolist()\n",
    "            target_maxprice.append(tmp_maxprice)\n",
    "\n",
    "            # taken bhs label\n",
    "            target_bhs.append( data.loc[seqlen-1+index, ['ws10_pt8_sl15']].values)\n",
    "\n",
    "            # max/min price within ws seqlength\n",
    "            max_v = max(data.loc[index:seqlen-1+index, ['open', 'high', 'low', 'close']].max())\n",
    "            min_v = min(data.loc[index:seqlen-1+index, ['open', 'high', 'low', 'close']].min())\n",
    "            # min_10 max_10 label scaled \n",
    "            target_minp_scaled.append((tmp_minprice-min_v)/(max_v-min_v))\n",
    "            target_maxp_scaled.append((tmp_maxprice-min_v)/(max_v-min_v))\n",
    "            # save\n",
    "            price_scaler_max.append(max_v)\n",
    "            price_scaler_min.append(min_v)\n",
    "            \n",
    "    # change to np.array astype()\n",
    "    train_arr_ohlc_scaled = np.array(train_dt_scaled).astype('float32')\n",
    "    train_arr_bb1 = np.array(train_dt_bb1).astype('int64')\n",
    "    train_arr_bb2 = np.array(train_dt_bb2).astype('int64')\n",
    "    train_arr_bb3 = np.array(train_dt_bb3).astype('int64')\n",
    "    train_arr_bb4 = np.array(train_dt_bb4).astype('int64')\n",
    "    train_arr_bb5 = np.array(train_dt_bb5).astype('int64')\n",
    "    train_arr_bb6 = np.array(train_dt_bb6).astype('int64')\n",
    "    train_arr_bb7 = np.array(train_dt_bb7).astype('int64')\n",
    "    train_arr_bb8 = np.array(train_dt_bb8).astype('int64')\n",
    "    train_arr_trend = np.array(train_dt_trend).astype('int64')\n",
    "    train_arr_change = np.array(train_dt_change).astype('int64')\n",
    "    train_arr_break = np.array(train_dt_break).astype('int64')\n",
    "    train_arr_rsi15 = np.array(train_dt_rsi15).astype('int64')\n",
    "    train_arr_rsi25 = np.array(train_dt_rsi25).astype('int64')\n",
    "    train_arr_rsi35 = np.array(train_dt_rsi35).astype('int64')\n",
    "    train_arr_wr_atr = np.array(train_dt_wr_atr).astype('float32')\n",
    "    target_minpArr_scaled = np.array(target_minp_scaled).astype('float32')\n",
    "    target_maxpArr_scaled = np.array(target_maxp_scaled).astype('float32') \n",
    "    target_arr_bhs = np.array(target_bhs).astype('int64')\n",
    "    \n",
    "    # save features and labels in dict {'OHLC' : np.array([ohlc])}\n",
    "    train_x_dict = {'OHLC':train_arr_ohlc_scaled,'bb1': train_arr_bb1,'bb2': train_arr_bb2,'bb3': train_arr_bb3,\n",
    "                    'bb4': train_arr_bb4,'bb5': train_arr_bb5,'bb6': train_arr_bb6,'bb7': train_arr_bb7,\n",
    "                    'bb8': train_arr_bb8,'TREND': train_arr_change,'CHANGE': train_arr_change,'BREAK': train_arr_break,\n",
    "                    'rsi15': train_arr_rsi15,'rsi25': train_arr_rsi25,'rsi35': train_arr_rsi35,'wr_atr':train_arr_wr_atr}\n",
    "\n",
    "    train_y_dict = {'minp': target_minpArr_scaled, 'maxp': target_maxpArr_scaled, 'bhs':target_arr_bhs}\n",
    "        \n",
    "        \n",
    "    return train_x_dict,train_y_dict, price_scaler_max,price_scaler_min,target_minprice, target_maxprice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "train_x_dict,train_y_dict,price_scaler_max,price_scaler_min,train_minprice, train_maxprice = generate_sequence(Xtrain,10)\n",
    "# validation set\n",
    "valid_x_dict,valid_y_dict,val_price_scaler_max,val_price_scaler_min,valid_minprice, valid_maxprice = generate_sequence(Xvalid,10)\n",
    "# test set\n",
    "test_x_dict,test_y_dict,test_price_scaler_max,test_price_scaler_min,test_minprice, test_maxprice = generate_sequence(Xtest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuary calculation\n",
    "def evaluate_regression_prediction(y_pred, y_true, model_name, printFlag=True):\n",
    "\n",
    "    errors = np.array(y_pred) - np.array(y_true)\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    mape = np.abs(100*errors/y_true).mean()\n",
    "    if printFlag:\n",
    "        print(model_name + ':')\n",
    "        print('Mean Absolute Error: {:.8f}'.format(mae))\n",
    "        print('Mean Absolute Percentage Error: {:.8f}'.format(mape))\n",
    "        print('Mean Square Error: {:.8f}'.format(mse))\n",
    "        print('Root Mean Square Error: {:.8f}'.format(rmse))\n",
    "        print('')\n",
    "\n",
    "    return mae, mape, mse, rmse\n",
    "\n",
    "def inverse_buyholdsell_label(output_ls):\n",
    "    # softmax vector find max one\n",
    "    temp = [0,0,0]\n",
    "    idx = 0   \n",
    "    for i in output_ls:\n",
    "        if i == max(output_ls):\n",
    "            temp[idx] = 1\n",
    "        idx+=1\n",
    "    return temp\n",
    "\n",
    "# Predict test\n",
    "def visualize_result(model, train_x_dict, train_y_dict,price_scaler_min, price_scaler_max,train_minprice,train_maxprice):\n",
    "    y_pred = model.predict(train_x_dict)\n",
    "    print('-' * 100)\n",
    "    print('MinMax Price Prediction Result: ')\n",
    "\n",
    "    # max\n",
    "    y_pred[0]\n",
    "    # min\n",
    "    y_pred[1]\n",
    "    # buy hold sell label\n",
    "    # y_pred[2]\n",
    "\n",
    "    # Inverse prediction to orginal scale\n",
    "    min_output,max_output = [],[]\n",
    "    for i in range(len(y_pred[0])):\n",
    "        #print(price_scaler_max[i] - price_scaler_min[i], y_pred[0][i] , price_scaler_min[i] )\n",
    "        max_output.append( (y_pred[0][i] * (price_scaler_max[i] - price_scaler_min[i])) + price_scaler_min[i] )\n",
    "        min_output.append( (y_pred[1][i] * (price_scaler_max[i] - price_scaler_min[i])) + price_scaler_min[i] )\n",
    "\n",
    "    a,b,c,d =evaluate_regression_prediction(max_output,train_maxprice,'Model')\n",
    "    a,b,c,d =evaluate_regression_prediction(min_output,train_minprice,'Model')\n",
    "\n",
    "\n",
    "    # Prediction result on Test set\n",
    "    plt.figure(2)\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(max_output, label='Max Predict')\n",
    "    #plt.plot(min_output, label='Min Predict')\n",
    "    #plt.plot(train_minprice, label='Actual Min Price') \n",
    "    plt.plot(train_maxprice, label='Actual Max Price') \n",
    "    plt.title('Predict Max & Actual Max')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(min_output, label='Min Predict')\n",
    "    plt.plot(train_minprice, label='Actual Min Price') \n",
    "    plt.title('Predict Min & Actual Min')\n",
    "    plt.legend(loc = 'upper right')\n",
    "\n",
    "    # Inverse buy hold sell prediction label\n",
    "    if len(y_pred) >2:\n",
    "        res = []\n",
    "        for i in y_pred[2]:\n",
    "            pre = inverse_buyholdsell_label(list(i))\n",
    "            res.append(pre)\n",
    "        \n",
    "\n",
    "        # res\n",
    "        ground_true = train_y_dict['bhs']\n",
    "        ground_true_matrix = to_categorical(ground_true)\n",
    "        # print(f'Accuracy for predicting buy hold sell label: {accuracy_score(res, valid_y_dict['bhs']):.4f}')\n",
    "        # accuracy_score(res, ground_true_matrix)\n",
    "\n",
    "        print(f'Accuracy for predicting buy hold sell label: {accuracy_score(ground_true_matrix,res):.4f}')\n",
    "        print(classification_report(ground_true_matrix,res))\n",
    "        print('-' * 100)\n",
    "        \n",
    "def visualize_history(history):\n",
    "    # visual_loss = ['maxp_loss', 'minp_loss', 'bhs_loss','val_maxp_loss', 'val_minp_loss', 'val_bhs_loss']\n",
    "    visual_loss = ['maxp_loss', 'minp_loss','val_maxp_loss', 'val_minp_loss']\n",
    "    visual_acc = ['Train Accuracy', 'Validation Accuracy']\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.figure(figsize=(15,6))\n",
    "    for i in visual_loss:\n",
    "        history.history[i]\n",
    "        plt.plot(history.epoch,history.history[i], label =i )\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc = 'upper right')\n",
    "\n",
    "    plt.figure(2)\n",
    "    history.history[i]\n",
    "    plt.bar(x = visual_acc, height = [history.history['bhs_acc'][-1],history.history['val_bhs_acc'][-1]] )\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Train & Validation')\n",
    "    plt.title('Label BuyHoldSell Prediction Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(seqlen, EMBED_DIM=4): \n",
    "    # feature input\n",
    "    input_ohlc = layers.Input((seqlen,4), dtype=tf.float32, name='OHLC')\n",
    "    input_bb1 = layers.Input((seqlen,), dtype=tf.int64, name='bb1')\n",
    "    input_bb2 = layers.Input((seqlen,), dtype=tf.int64, name='bb2')\n",
    "    input_bb3 = layers.Input((seqlen,), dtype=tf.int64, name='bb3')\n",
    "    input_bb4 = layers.Input((seqlen,), dtype=tf.int64, name='bb4')\n",
    "    input_bb5 = layers.Input((seqlen,), dtype=tf.int64, name='bb5')\n",
    "    input_bb6 = layers.Input((seqlen,), dtype=tf.int64, name='bb6')\n",
    "    input_bb7 = layers.Input((seqlen,), dtype=tf.int64, name='bb7')\n",
    "    input_bb8 = layers.Input((seqlen,), dtype=tf.int64, name='bb8')\n",
    "    input_TREND = layers.Input((seqlen,), dtype=tf.int64, name='TREND')\n",
    "    input_CHANGE = layers.Input((seqlen,), dtype=tf.int64, name='CHANGE')\n",
    "    input_BREAK = layers.Input((seqlen,), dtype=tf.int64, name='BREAK')\n",
    "    input_rsi15 = layers.Input((seqlen,), dtype=tf.int64, name='rsi15')\n",
    "    input_rsi25 = layers.Input((seqlen,), dtype=tf.int64, name='rsi25')\n",
    "    input_rsi35 = layers.Input((seqlen,), dtype=tf.int64, name='rsi35')\n",
    "    input_wr_atr = layers.Input((seqlen,6), dtype=tf.float32, name='wr_atr')\n",
    "    # categorical embedding layer (input_dim = categorical number+1)\n",
    "    emb_bb1 = layers.Embedding(3, EMBED_DIM, name='bb1_embedding')(input_bb1)\n",
    "    emb_bb2 = layers.Embedding(3, EMBED_DIM, name='bb2_embedding')(input_bb2)\n",
    "    emb_bb3 = layers.Embedding(3, EMBED_DIM, name='bb3_embedding')(input_bb3)\n",
    "    emb_bb4 = layers.Embedding(3, EMBED_DIM, name='bb4_embedding')(input_bb4)\n",
    "    emb_bb5 = layers.Embedding(3, EMBED_DIM, name='bb5_embedding')(input_bb5)\n",
    "    emb_bb6 = layers.Embedding(3, EMBED_DIM, name='bb6_embedding')(input_bb6)\n",
    "    emb_bb7 = layers.Embedding(3, EMBED_DIM, name='bb7_embedding')(input_bb7)\n",
    "    emb_bb8 = layers.Embedding(3, EMBED_DIM, name='bb8_embedding')(input_bb8)\n",
    "    emb_TREND = layers.Embedding(3, EMBED_DIM, name='TREND_embedding')(input_TREND)\n",
    "    emb_CHANGE = layers.Embedding(4, EMBED_DIM, name='CHANGE_embedding')(input_CHANGE)\n",
    "    emb_BREAK = layers.Embedding(3, EMBED_DIM, name='BREAK_embedding')(input_BREAK)\n",
    "    emb_rsi15 = layers.Embedding(4, EMBED_DIM, name='rsi15_embedding')(input_rsi15)\n",
    "    emb_rsi25 = layers.Embedding(4, EMBED_DIM, name='rsi25_embedding')(input_rsi25)\n",
    "    emb_rsi35 = layers.Embedding(4, EMBED_DIM, name='rsi35_embedding')(input_rsi35)\n",
    "    # input features to model \n",
    "    features_bb1 = layers.LSTM(128,dropout=0.2)(emb_bb1)\n",
    "    features_bb2 = layers.LSTM(128,dropout=0.2)(emb_bb2)\n",
    "    features_bb3 = layers.LSTM(128,dropout=0.2)(emb_bb3)\n",
    "    features_bb4 = layers.LSTM(128,dropout=0.2)(emb_bb4)\n",
    "    features_bb5 = layers.LSTM(128,dropout=0.2)(emb_bb5)\n",
    "    features_bb6 = layers.LSTM(128,dropout=0.2)(emb_bb6)\n",
    "    features_bb7 = layers.LSTM(128,dropout=0.2)(emb_bb7)\n",
    "    features_bb8 = layers.LSTM(128,dropout=0.2)(emb_bb8)\n",
    "    features_TREND = layers.LSTM(128,dropout=0.2)(emb_TREND)\n",
    "    features_CHANGE = layers.LSTM(128,dropout=0.2)(emb_CHANGE)\n",
    "    features_BREAK = layers.LSTM(128,dropout=0.2)(emb_BREAK)\n",
    "    features_rsi15 = layers.LSTM(128,dropout=0.2)(emb_rsi15)\n",
    "    features_rsi25 = layers.LSTM(128,dropout=0.2)(emb_rsi25)\n",
    "    features_rsi35 = layers.LSTM(128,dropout=0.2)(emb_rsi35)\n",
    "    features_wr_atr = layers.LSTM(128,dropout=0.2)(input_wr_atr)\n",
    "    features_ohlc = layers.LSTM(128, return_sequences=False)(input_ohlc)\n",
    "    features_all = layers.concatenate([features_bb1, features_bb2, features_bb3, features_bb4, features_bb5, \n",
    "                                       features_bb6, features_bb7, features_bb8, features_TREND, features_CHANGE, \n",
    "                                       features_BREAK, features_rsi15, features_rsi25, features_rsi35,features_wr_atr,\n",
    "                                       features_ohlc])\n",
    "    # dropout, layernormalization \n",
    "    \n",
    "    output_maxp = layers.Dense(1, name='maxp')(features_all)\n",
    "    output_minp = layers.Dense(1, name='minp')(features_all)\n",
    "    # bhs labels\n",
    "    output_buyholdsell = layers.Dense(3, activation=\"softmax\", name = 'bhs')(features_all)\n",
    "    \n",
    "    model = keras.Model(\n",
    "                inputs=[input_ohlc, input_bb1, input_bb2, input_bb3, input_bb4, input_bb5, input_bb6, \n",
    "                        input_bb7, input_bb8, input_TREND, input_CHANGE, input_BREAK, input_rsi15, \n",
    "                        input_rsi25, input_rsi35,input_wr_atr],\n",
    "                outputs=[output_maxp, output_minp,output_buyholdsell],\n",
    "            )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=0.001),\n",
    "        loss={\n",
    "            \"maxp\": 'mse',\n",
    "            \"minp\":'mse',\n",
    "            'bhs' : 'SparseCategoricalCrossentropy',\n",
    "        },\n",
    "        metrics={\n",
    "            \"maxp\": tf.keras.metrics.RootMeanSquaredError(),\n",
    "            \"minp\": tf.keras.metrics.RootMeanSquaredError(),\n",
    "            'bhs' :'acc',\n",
    "        }\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = buildModel(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: {batch size : [32, 64 , 128, 256] epoch:[50,100,300,500...]}\n",
    "history = LSTM_model.fit(train_x_dict, train_y_dict, epochs=30, \n",
    "    batch_size=256,verbose = 1, validation_data=(valid_x_dict, valid_y_dict), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "LSTM_model.save('AUDCAD/LSTM_model_min10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(LSTM_model,valid_x_dict, valid_y_dict, val_price_scaler_min, val_price_scaler_max,valid_minprice,valid_maxprice)\n",
    "\n",
    "visualize_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_Bi_LSTM(seqlen, EMBED_DIM=4): \n",
    "    # feature input\n",
    "    input_ohlc = layers.Input((seqlen,4), dtype=tf.float32, name='OHLC')\n",
    "    input_bb1 = layers.Input((seqlen,), dtype=tf.int64, name='bb1')\n",
    "    input_bb2 = layers.Input((seqlen,), dtype=tf.int64, name='bb2')\n",
    "    input_bb3 = layers.Input((seqlen,), dtype=tf.int64, name='bb3')\n",
    "    input_bb4 = layers.Input((seqlen,), dtype=tf.int64, name='bb4')\n",
    "    input_bb5 = layers.Input((seqlen,), dtype=tf.int64, name='bb5')\n",
    "    input_bb6 = layers.Input((seqlen,), dtype=tf.int64, name='bb6')\n",
    "    input_bb7 = layers.Input((seqlen,), dtype=tf.int64, name='bb7')\n",
    "    input_bb8 = layers.Input((seqlen,), dtype=tf.int64, name='bb8')\n",
    "    input_TREND = layers.Input((seqlen,), dtype=tf.int64, name='TREND')\n",
    "    input_CHANGE = layers.Input((seqlen,), dtype=tf.int64, name='CHANGE')\n",
    "    input_BREAK = layers.Input((seqlen,), dtype=tf.int64, name='BREAK')\n",
    "    input_rsi15 = layers.Input((seqlen,), dtype=tf.int64, name='rsi15')\n",
    "    input_rsi25 = layers.Input((seqlen,), dtype=tf.int64, name='rsi25')\n",
    "    input_rsi35 = layers.Input((seqlen,), dtype=tf.int64, name='rsi35')\n",
    "    input_wr_atr = layers.Input((seqlen,6), dtype=tf.float32, name='wr_atr')\n",
    "    # categorical embedding layer \n",
    "    emb_bb1 = layers.Embedding(3, EMBED_DIM, name='bb1_embedding')(input_bb1)\n",
    "    emb_bb2 = layers.Embedding(3, EMBED_DIM, name='bb2_embedding')(input_bb2)\n",
    "    emb_bb3 = layers.Embedding(3, EMBED_DIM, name='bb3_embedding')(input_bb3)\n",
    "    emb_bb4 = layers.Embedding(3, EMBED_DIM, name='bb4_embedding')(input_bb4)\n",
    "    emb_bb5 = layers.Embedding(3, EMBED_DIM, name='bb5_embedding')(input_bb5)\n",
    "    emb_bb6 = layers.Embedding(3, EMBED_DIM, name='bb6_embedding')(input_bb6)\n",
    "    emb_bb7 = layers.Embedding(3, EMBED_DIM, name='bb7_embedding')(input_bb7)\n",
    "    emb_bb8 = layers.Embedding(3, EMBED_DIM, name='bb8_embedding')(input_bb8)\n",
    "    emb_TREND = layers.Embedding(3, EMBED_DIM, name='TREND_embedding')(input_TREND)\n",
    "    emb_CHANGE = layers.Embedding(4, EMBED_DIM, name='CHANGE_embedding')(input_CHANGE)\n",
    "    emb_BREAK = layers.Embedding(3, EMBED_DIM, name='BREAK_embedding')(input_BREAK)\n",
    "    emb_rsi15 = layers.Embedding(4, EMBED_DIM, name='rsi15_embedding')(input_rsi15)\n",
    "    emb_rsi25 = layers.Embedding(4, EMBED_DIM, name='rsi25_embedding')(input_rsi25)\n",
    "    emb_rsi35 = layers.Embedding(4, EMBED_DIM, name='rsi35_embedding')(input_rsi35)\n",
    "    # input feature to model\n",
    "    features_bb1 = layers.Bidirectional(layers.LSTM(128))(emb_bb1)\n",
    "    features_bb2 = layers.Bidirectional(layers.LSTM(128))(emb_bb2)\n",
    "    features_bb3 = layers.Bidirectional(layers.LSTM(128))(emb_bb3)\n",
    "    features_bb4 = layers.Bidirectional(layers.LSTM(128))(emb_bb4)\n",
    "    features_bb5 = layers.Bidirectional(layers.LSTM(128))(emb_bb5)\n",
    "    features_bb6 = layers.Bidirectional(layers.LSTM(128))(emb_bb6)\n",
    "    features_bb7 = layers.Bidirectional(layers.LSTM(128))(emb_bb7)\n",
    "    features_bb8 = layers.Bidirectional(layers.LSTM(128))(emb_bb8)\n",
    "    features_TREND = layers.Bidirectional(layers.LSTM(128))(emb_TREND)\n",
    "    features_CHANGE = layers.Bidirectional(layers.LSTM(128))(emb_CHANGE)\n",
    "    features_BREAK = layers.Bidirectional(layers.LSTM(128))(emb_BREAK)\n",
    "    features_rsi15 = layers.LSTM(128)(emb_rsi15)\n",
    "    features_rsi25 = layers.LSTM(128)(emb_rsi25)\n",
    "    features_rsi35 = layers.LSTM(128)(emb_rsi35)\n",
    "    features_wr_atr = layers.LSTM(128)(input_wr_atr)\n",
    "    features_ohlc = layers.Bidirectional(layers.LSTM(128))(input_ohlc)\n",
    "    features_all = layers.concatenate([features_bb1, features_bb2, features_bb3, features_bb4, features_bb5, \n",
    "                                       features_bb6, features_bb7, features_bb8, features_TREND, features_CHANGE, \n",
    "                                       features_BREAK, features_rsi15, features_rsi25, features_rsi35,\n",
    "                                       features_wr_atr,features_ohlc])\n",
    "    # dropout, layernormalization \n",
    "    \n",
    "    \n",
    "    output_maxp = layers.Dense(1, name='maxp')(features_all)\n",
    "    output_minp = layers.Dense(1, name='minp')(features_all)\n",
    "    # bhs label\n",
    "    output_buyholdsell = layers.Dense(3, activation=\"softmax\", name = 'bhs')(features_all)\n",
    "   \n",
    "    \n",
    "    model = keras.Model(\n",
    "                inputs=[input_ohlc, input_bb1, input_bb2, input_bb3, input_bb4, input_bb5, input_bb6, \n",
    "                       input_bb7, input_bb8, input_TREND, input_CHANGE, input_BREAK,input_rsi15, \n",
    "                        input_rsi25, input_rsi35,input_wr_atr ],\n",
    "                outputs=[output_maxp, output_minp,output_buyholdsell],\n",
    "            )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=0.001),\n",
    "        loss={\n",
    "            \"maxp\": 'mse',\n",
    "            \"minp\":'mse',\n",
    "            'bhs' : 'SparseCategoricalCrossentropy',\n",
    "        },\n",
    "        metrics={\n",
    "            \"maxp\": tf.keras.metrics.RootMeanSquaredError(),\n",
    "            \"minp\": tf.keras.metrics.RootMeanSquaredError(),\n",
    "            'bhs' :'acc',\n",
    "        }\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bi_LSTM_Model = buildModel_Bi_LSTM(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: {batch size : [32, 64 , 128, 256] epoch:[50,100,300,500...]}\n",
    "history = Bi_LSTM_Model.fit(train_x_dict, train_y_dict, \n",
    "          epochs=30, \n",
    "          batch_size=256,verbose = 1, validation_data=(valid_x_dict ,valid_y_dict), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "Bi_LSTM_Model.save('path/Bi_LSTM_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(LSTM_model,valid_x_dict, valid_y_dict, val_price_scaler_min, val_price_scaler_max,valid_minprice,valid_maxprice)\n",
    "# visualize_result(transformer,test_x_dict, test_price_scaler_min,test_price_scaler_max,test_minprice, test_maxprice)\n",
    "visualize_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 256\n",
    "embed_dim = 64 # Embedding size for attention\n",
    "head_size = 64\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
    "dropout_rate = 0.3\n",
    "num_blocks = 2\n",
    "\n",
    "\n",
    "def get_position_encoding(seq_len, d, n=10000):\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    return P\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.2):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "    \n",
    "def build_model(input_shape,EMBED_DIM, head_size, num_heads, ff_dim, num_transformer_blocks, dropout=0.2, mlp_dropout=0.2):\n",
    "\n",
    "    # feature input\n",
    "    input_ohlc = layers.Input((input_shape,4), dtype=tf.float32, name='OHLC')\n",
    "    input_bb1 = layers.Input((input_shape,), dtype=tf.int64, name='bb1')\n",
    "    input_bb2 = layers.Input((input_shape,), dtype=tf.int64, name='bb2')\n",
    "    input_bb3 = layers.Input((input_shape,), dtype=tf.int64, name='bb3')\n",
    "    input_bb4 = layers.Input((input_shape,), dtype=tf.int64, name='bb4')\n",
    "    input_bb5 = layers.Input((input_shape,), dtype=tf.int64, name='bb5')\n",
    "    input_bb6 = layers.Input((input_shape,), dtype=tf.int64, name='bb6')\n",
    "    input_bb7 = layers.Input((input_shape,), dtype=tf.int64, name='bb7')\n",
    "    input_bb8 = layers.Input((input_shape,), dtype=tf.int64, name='bb8')\n",
    "    input_TREND = layers.Input((input_shape,), dtype=tf.int64, name='TREND')\n",
    "    input_CHANGE = layers.Input((input_shape,), dtype=tf.int64, name='CHANGE')\n",
    "    input_BREAK = layers.Input((input_shape,), dtype=tf.int64, name='BREAK')\n",
    "    input_rsi15 = layers.Input((input_shape,), dtype=tf.int64, name='rsi15')\n",
    "    input_rsi25 = layers.Input((input_shape,), dtype=tf.int64, name='rsi25')\n",
    "    input_rsi35 = layers.Input((input_shape,), dtype=tf.int64, name='rsi35')\n",
    "    input_wr_atr = layers.Input((input_shape,6), dtype=tf.float32, name='wr_atr')\n",
    "\n",
    "    # categorical embedding layer \n",
    "    # generate postional embedding\n",
    "    positional_embedding = get_position_encoding(20,906)\n",
    "    \n",
    "    emb_bb1 = layers.Embedding(3, EMBED_DIM, name='bb1_embedding')(input_bb1)\n",
    "    emb_bb2 = layers.Embedding(3, EMBED_DIM, name='bb2_embedding')(input_bb2)\n",
    "    emb_bb3 = layers.Embedding(3, EMBED_DIM, name='bb3_embedding')(input_bb3)\n",
    "    emb_bb4 = layers.Embedding(3, EMBED_DIM, name='bb4_embedding')(input_bb4)\n",
    "    emb_bb5 = layers.Embedding(3, EMBED_DIM, name='bb5_embedding')(input_bb5)\n",
    "    emb_bb6 = layers.Embedding(3, EMBED_DIM, name='bb6_embedding')(input_bb6)\n",
    "    emb_bb7 = layers.Embedding(3, EMBED_DIM, name='bb7_embedding')(input_bb7)\n",
    "    emb_bb8 = layers.Embedding(3, EMBED_DIM, name='bb8_embedding')(input_bb8)\n",
    "    emb_TREND = layers.Embedding(3, EMBED_DIM, name='TREND_embedding')(input_TREND)\n",
    "    emb_CHANGE = layers.Embedding(4, EMBED_DIM, name='CHANGE_embedding')(input_CHANGE)\n",
    "    emb_BREAK = layers.Embedding(3, EMBED_DIM, name='BREAK_embedding')(input_BREAK)\n",
    "    emb_rsi15 = layers.Embedding(4, EMBED_DIM, name='rsi15_embedding')(input_rsi15)\n",
    "    emb_rsi25 = layers.Embedding(4, EMBED_DIM, name='rsi25_embedding')(input_rsi25)\n",
    "    emb_rsi35 = layers.Embedding(4, EMBED_DIM, name='rsi35_embedding')(input_rsi35)\n",
    "    \n",
    "    # INPUT EMBEDDING LAYER\n",
    "    x = layers.Concatenate()([emb_bb1, emb_bb2, emb_bb3, emb_bb4, emb_bb5, \n",
    "                              emb_bb6, emb_bb7, emb_bb8, emb_TREND, emb_CHANGE,\n",
    "                              emb_BREAK,emb_rsi15,emb_rsi25,emb_rsi35,input_wr_atr, input_ohlc])\n",
    "\n",
    "    x = x+ positional_embedding\n",
    "    x = layers.Dense(feat_dim)(x)\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    \n",
    "    # pointwise mlp\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(mlp_dropout)(x)\n",
    "    output_maxp = layers.Dense(1, name='maxp')(x)\n",
    "    output_minp = layers.Dense(1, name='minp')(x)\n",
    "    \n",
    "    # CLASSIFICATION \n",
    "    outputs_bhs = layers.Dense(4, activation=\"softmax\", name='bhs')(x)\n",
    "    model = keras.Model(\n",
    "                inputs=[input_ohlc, input_bb1, input_bb2, input_bb3, input_bb4, input_bb5, input_bb6, \n",
    "                       input_bb7, input_bb8, input_TREND, input_CHANGE, input_BREAK, input_rsi15,input_rsi25,\n",
    "                       input_rsi35,input_wr_atr],\n",
    "                outputs=[output_maxp, output_minp,outputs_bhs],\n",
    "            )\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss={\n",
    "            \"maxp\": 'mse',\n",
    "            \"minp\":'mse',\n",
    "            'bhs' : 'SparseCategoricalCrossentropy',\n",
    "        },\n",
    "        metrics={\n",
    "            \"maxp\": tf.keras.metrics.RootMeanSquaredError(),\n",
    "            \"minp\": tf.keras.metrics.RootMeanSquaredError(),\n",
    "            'bhs' :'acc',\n",
    "        }\n",
    "    )\n",
    "    model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = build_model(20, head_size, embed_dim,num_heads, ff_dim, num_blocks, dropout=dropout_rate, mlp_dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = transformer.fit(train_x_dict, train_y_dict, \n",
    "                          epochs=30,\n",
    "                          batch_size=256,verbose = 1, validation_data=(valid_x_dict ,valid_y_dict), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "transformer.save('AUDCAD/transformer_min10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(transformer,valid_x_dict, valid_y_dict, val_price_scaler_min, val_price_scaler_max,valid_minprice,valid_maxprice)\n",
    "\n",
    "visualize_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
